Make Your Search Better

In the previous chapter, we learned how to extend our index with additional information and how to handle highlighting and indexing data that is not flat. We also implemented an autocomplete
mechanism using ElasticSearch, indexed files, and geographical information. However, by the end of this chapter, you will have learned the following:

Why your document was matched
How to influence document score
How to use synonyms
How to handle multilingual data
How to use term position aware queries (span queries)


Why this document was found

Compared to databases, using systems capable of performing full-text search can often be anything other than obvious. We can search in many fields simultaneously and the data in the index
can vary from those provided for indexing because of the analysis process, synonyms, language analysis, abbreviations, and others.
It's even worse; by default, search engines sort data by scoring—a number that indicates how many current documents fit into the current searching criteria. For this, "how much" is the key;
search takes into consideration many factors such as how many searched words were found in the document, how frequent is this word in the whole index, and how long is the field.
This seems complicated and finding out why a document was found and why another document is "better" is not easy.
Fortunately, ElasticSearch has some tools that can answer these questions. Let's take a look at them


Understanding how a field is analyzed

One of the common questions asked is why a given document was not found. In many cases, the problem lies in the definition of the mappings and the configuration of the analysis process.
For debugging an analysis, ElasticSearch provides a dedicated REST API endpoint. Let's see a few examples on how to use this API.The first query asks ElasticSearch for information about
the analysis process, using the default analyzer:

curl -XGET 'localhost:9200/_analyze?pretty' -d 'Crime and Punishment'

In response, we get the following data:

{
  "tokens" : [ {
    "token" : "crime",
    "start_offset" : 0,
    "end_offset" : 5,
    "type" : "<ALPHANUM>",
    "position" : 1
  }, {
    "token" : "punishment",
    "start_offset" : 10,
    "end_offset" : 20,
    "type" : "<ALPHANUM>",
    "position" : 3
  } ]
}

As we can see, ElasticSearch divided the input phrase into two tokens. During processing, the "and" common word was omitted (because it belongs to the stop words list) and the other words
were changed to lowercase versions. Now let's take a look at something more complicated. In "Extending Your Structure and Search", when we talked about the autocomplete feature,
we used the edge engram filter. Let's recall this index and see how our analyzer works in that case:

curl -XGET 'localhost:9200/addressbook/_analyze?analyzer=autocomplete&pretty' -d 'John Smith'

In the preceding call, we used an additional parameter named "analyzer", which you should already be familiar with—it tells ElasticSearch which analyzer should be used instead of the
default one. Look at the returned result:

{
  "tokens" : [ {
    "token" : "joh",
    "start_offset" : 0,
    "end_offset" : 3,
    "type" : "word",
    "position" : 1
  }, {
    "token" : "john",
    "start_offset" : 0,
    "end_offset" : 4,
    "type" : "word",
    "position" : 2
  }, {
    "token" : "smi",
    "start_offset" : 5,
    "end_offset" : 8,
    "type" : "word",
    "position" : 3
  }, {
    "token" : "smit",
    "start_offset" : 5,
    "end_offset" : 9,
    "type" : "word",
    "position" : 4
  }, {
    "token" : "smith",
    "start_offset" : 5,
    "end_offset" : 10,
    "type" : "word",
    "position" : 5
  } ]
}

This time, in addition to lowercasing and splitting words, we used the edge engram filter. Our phrase was divided into tokens and lowercased. Please note that the minimum length
of the generated prefixes was three letters.

It is worth noting that there is another form of analysis API available—one that allows us to provide tokenizers and filters. It is very handy when we want to experiment with a configuration
before creating the target mappings. An example of such a call is as follows:

curl -XGET 'localhost:9200/addressbook/_analyze?tokenizer=whitespace&filters=lowercase,engram&pretty' -d 'John Smith'

In the preceding example, we used an analyzer that was built from the "whitespace" tokenizer and the two filters "lowercase" and "engram".

As we can see, an analysis API can be very useful for tracking down bugs in the mapping configuration, but when we want to solve problems with queries and search relevance, explanation
from the API is invaluable. It can show us how our analyzers work, what terms they produce, and what are the attributes of those terms. With such information, analyzing query problems
will be easier to track down.


Explaining the query

Let's look at the following example:

curl -XGET 'localhost:9200/library/book/1/_explain?pretty&q=quiet'

In the preceding call, we provided a specific document and a query to run. Using the _explain endpoint, we ask ElasticSearch for an explanation about how the document was matched
(or not matched) by ElasticSearch. For example, should the preceding document be found by the provided query? If it is found, ElasticSearch will provide the information why the document
was matched with the details about how its score was calculated:

{
  "ok" : true,
  "matches" : true,
  "explanation" : {
    "value" : 0.057534903,
    "description" : "fieldWeight(_all:quiet in 0), product of:",
    "details" : [ {
      "value" : 1.0,
      "description" : "tf(termFreq(_all:quiet)=1)"
    }, {
      "value" : 0.30685282,
      "description" : "idf(docFreq=1, maxDocs=1)"
    }, {
      "value" : 0.1875,
      "description" : "fieldNorm(field=_all, doc=0)"
    } ]
  }
}

Looks complicated, doesn't it? Well, it is complicated and is even worse if we realize that this is only a simple query! ElasticSearch, and more specifically the Lucene library, shows
the internal information of the scoring process. We will only scratch the surface and will explain the most important things.

The most important part is the total score calculated for a document. If it is equal to 0, the document won't match the given query. Another important element is the description that tells
us about different scoring components. Depending on the query type, components may affect the final score in a different way. In our case, the total score is a product of the scores
calculated by all the components.

The detailed information about components and knowing where we should seek for an explanation and why our document matches the query is also important. In this example, we were looking
for the "quiet" word. It was found in the _all field. It is obvious because we searched in the default field, which is _all (you should remember from Chapter Extending Your Structure
and Search, that this is the field where all indexed data is copied by default to make a default search field available).

In the preceding response, you can also read information about the term frequency in the given field (which was 1 in our case). This means that the field contained only a single occurrence
of the searched term. And finally, the last piece of information; maxDocs equals to 1, which means that only one document was found with the specified term. This usually means that
we are dealing with a small index or we've searched with the use of very rare word.


Influencing scores with query boosts

In the previous chapter, we learned how to check why the search returns a given document and what factors had influence on its position in the result list. When an application grows,
the need for improving the quality of search also increases—so-called search experience. We need to gain knowledge about what is more important to the user and to see how users use
the search functionality. This leads to various conclusions; for example, we see that some parts of the documents are more important than the others or that particular queries emphasize
one field at the cost of others. This is where boosting can be used. In the previous chapters, we've seen some information about boosting. In this chapter, we'll summarize this knowledge
and we will show how to use it in practice.


What is boost?

"Boost" is an additional value used in the process of scoring. We can apply this value to the following:
Query:
    This is a way to inform the search engine that the given query that is a part of a complex query is more significant than the others.
Field:
    Several document fields are important for the user. For example, searching e-mails by Bill should probably list those from Bill first, next those with Bill in subject,
    and then e-mails mentioning Bill in contents.
Document:
    Sometimes some documents are more important. In our example, with e-mail searching, e-mails from our friend are usually more important than e-mails from an unknown man.
    
Values assigned by us to a query, field, or document are only one factor used when we calculate the resulting score. We will now look at a few examples of query boosting


Adding boost to queries

Let's imagine that our index has two documents:

{
  "id" : 1,
  "to" : "John Smith",
  "from" : "David Jones",
  "subject" : "Top secret!"
}

And:

{
  "id" : 2,
  "to" : "David Jones",
  "from" : "John Smith",
  "subject" : "John, read this document"
}

This data is trivial, but it should describe our problem very well. Now let's assume we have the following query:

{
  "query" : {
    "query_string" : {
       "query" : "john",
       "use_dis_max" : false
    }
  }
}

In this case, ElasticSearch will create a query to the _all field and will find documents that contain desired words. We also said that we don't want a disjunction query to be used by
specifying the use_dis_max parameter to false (if you don't remember what a disjunction query is, please refer to the Explaining the query string section dedicated to querying a string query
in Chapter "Searching Your Data"). As we can easily guess, both our records will be returned and the record with ID equals to 2 will be first because of two occurrences of John in the from
and subject fields. Let's check this out in the following result:

"hits" : {
    "total" : 2,
    "max_score" : 0.16273327,
    "hits" : [ {
      "_index" : "messages",
      "_type" : "email",
      "_id" : "2",
      "_score" : 0.16273327, "_source" : 
      { "to" : "David Jones", "from" : 
      "John Smith", "subject" : "John, read this document"}
    }, {
      "_index" : "messages",
      "_type" : "email",
      "_id" : "1",
      "_score" : 0.11506981, "_source" : 
      { "to" : "John Smith", "from" : 
      "David Jones", "subject" : "Top secret!" }
    } ]
}

Is everything all right? Technically, yes. But I think that the second document should be positioned as the first one in the result list, because when searching for something, the most
important factor (in many cases) is matching people, rather than the subject of the message. You can disagree, but this is exactly why full-text searching relevance is a difficult
topic—sometimes it is hard to tell which ordering is better for a particular case. What can we do? First, let's rewrite our query to implicitly inform ElasticSearch what fields should be
used for searching:

{
  "query" : {
    "query_string" : {
      "fields" : ["from", "to", "subject"],
      "query" : "john",
      "use_dis_max" : false
    }
  }
}

This is not exactly the same query as the previous one. If we run it, we will get the same results (in our case), but if you look carefully, you will notice differences in scoring.
In the previous example, ElasticSearch only used one field, _all. Now we are searching in three fields. This means that several factors, such as field lengths, are changed.
Anyway, this is not so important in our case. ElasticSearch, under the hood, generates a complex query made of three queries—one to each field so that fields are treated equally.
Of course, the score contributed by each query depends on the number of terms found in this field and the length of this field. Let's introduce some differences between fields.
Compare the following query to the previous one:

{
  "query" : {
    "query_string" : {
      "fields" : ["from^5", "to^10", "subject"],
      "query" : "john",
      "use_dis_max" : false
    }
  }
}

Look at the highlighted parts (^5 and ^10). In this way, we can tell ElasticSearch how important a given field is. We see that the most important field is "to" and the "from" field is
less important. The subject field has the default value for boost, which is 1.0. Always remember that this value is only one of various factors. You may be wondering why we choose 5,
not 1000 or 1.23. Well, this value depends on the effect we want to achieve, what query we have, and most importantly, what data we have in our index. This is the important part because
this means that when data changes in the meaningful parts, we should probably check and tune our relevance once again.
Finally, let's look at a similar example, but using the bool query:

{
 "query" : {
  "bool" : {
   "should" : [
    { "term" : { "from": { "value" : "john", "boost" : 5 }}},
    { "term" : { "to": { "value" : "john", "boost" : 10  }}},
    { "term" : { "subject": { "value" : "john" }}}
   ]
  }
 }
}


Modifying the score

The preceding example shows how to affect the result list by boosting particular query components. Another technique is to run a query and affect the score of the documents returned by
this query. In the following sections, we will summarize the possibilities offered by ElasticSearch. In the examples, we will use our library data from the second chapter.


Constant score query

A constant score query allows us to take any filter or query and explicitly set the value that should be used as the score that will be given for each matching document.
At first, this query doesn't seem to be practical. But when we think about building complex queries, this query allows us to set how many documents matching this query can affect
the total score. Look at the following example:

{
  "query" : {
    "constant_score" : {
      "query": {
        "query_string" : {
          "query" : "available:false author:heller"
        }
      },
      "boost": 5.0
    }
  }
}

In our library data that we have used, we have two documents with the "available" field set to false. One of these documents has an additional value in the "author" field.
But thanks to the constant score query, ElasticSearch will ignore that information. Both documents will be given a score equal to… 1.0. Strange? Not if we think about normalization
that happens during indexing. In this stage, ElasticSearch saved additional information and changed the resulting score in order for this score to be comparable with the other parts
of this query. It doesn't matter if our query contains only a single part. Note that in our example, we've used a query, but we can also use a filter.
This is also better for performance reasons. For clarity, let's look at the following example with a filter:

{
  "query" : {
    "constant_score" : {
      "filter": {
        "term" : {
          "available" : false
        }
      },
      "boost": 5.0
    }
  }
}


Custom boost factor query

This query is similar to the previous one. Let's start with an example:

{
  "query" : {
    "custom_boost_factor" : {
      "query": {
        "query_string" : {
          "query" : "available:false author:heller"
        }
      },
      "boost_factor": 5.0
    }
  }
}

In this case, the resulting score is multiplied by boost_factor. Unlike the previous query, this version doesn't support filters instead of queries.


Boosting query

The next type of query connected with boosting is the boosting query. The idea is to allow us to define an additional part of a query, where the score of every matched document decreases.
The following example lists all the available books, but books written by E. M. Remarque will have a score of 10 times lower:

{
  "query" : {
    "boosting" : {
      "positive" : {
        "term" : {
          "available" : true
        }
      },
      "negative" : {
        "term" : {
          "author" : "remarque"
        }
      },
      "negative_boost" : 0.1
    }
  }
}


Custom score query

The custom score query gives us the simple possibility to set a score for all matched documents. It allows us to attach additional logic defined by a script to every matching document.
Of course, this way of influencing a score is much slower, but sometimes it is the most convenient and the simplest way, so we should be aware of its existence and its possible usage.
For example:

{
  "query" : {
    "custom_score" : {
      "query" : {
        "matchAll" : {}
      },
      "script" : "doc['copies'].value * 0.5"
    }
  },
  "fields" : ["title", "copies"]
}

This query matches all documents in the index. We've wrapped this query with the custom_score element and thanks to it, we can use an additional script for score calculation. In our example,
we've used a very simple script. We just return the score as a half of the copies field value. For clarity, we use the fields element to get only the values for the title and copies fields.
And now, what we obtain in return is as follows:

"hits" : [ {
      "_index" : "library",
      "_type" : "book",
      "_id" : "2",
      "_score" : 3.0,
      "fields" : {
        "title" : "Catch-22",
        "copies" : 6
      }
    }, {
      "_index" : "library",
      "_type" : "book",
      "_id" : "1",
      "_score" : 0.5,
      "fields" : {
        "title" : "All Quiet on the Western Front",
        "copies" : 1
      }
    }, {
      "_index" : "library",
      "_type" : "book",
      "_id" : "4",
      "_score" : 0.0,
      "fields" : {
        "title" : "Crime and Punishment",
        "copies" : 0
      }
    }, {
      "_index" : "library",
      "_type" : "book",
      "_id" : "3",
      "_score" : 0.0,
      "fields" : {
        "title" : "The Complete Sherlock Holmes",
        "copies" : 0
      }
} ]
    
ElasticSearch did what we wanted, but look what happens when the "copies" field is set to 0. The score is also 0! Normally this means that document doesn't match the query.
We should remember that score manipulation doesn't allow us to reject any documents from the result.


Custom filters score query


