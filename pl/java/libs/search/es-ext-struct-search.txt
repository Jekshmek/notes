Indexing data that is not flat

Not all data is flat like that which we have been using since the previous chapter. Of course if we are building our system, which ElasticSearch will be a part of,
we can create a structure that is convenient for ElasticSearch. However, it doesn't need to be flat, it can be more object-oriented.
Let's see how to create mappings that use fully structured JSON objects

Data

Let's assume we have the following data (we store it in the file called structured_data.json):
{
 "book" : {
  "author" : {
   "name" : {
    "firstName" : "Fyodor",
    "lastName" : "Dostoevsky"
   }
  },
  "isbn" : "123456789",
  "englishTitle" : "Crime and Punishment",
  "originalTitle" : "????????é??? ? ?????á???",
  "year" : 1886,
  "characters" : [
   {
    "name" : "Raskolnikov"
   }, 
   {
    "name" : "Sofia"
   }
  ],
  "copies" : 0
  }
}

As you can see, the data is not flat. It contains arrays and nested objects, so we can't use our mappings that we used previously. But we can create mappings that will be able to handle such data

Objects

The previous example data shows a structured JSON file. As you can see, the root object in our file is book. The root object is a special one, which allows us to define additional properties.
The book root object has some simple properties such as englishTitle, originalTitle, and so on. Those will be indexed as normal fields in the index.

In addition to that it has the characters array type, which we will discuss in the next paragraph. For now, let's focus on author. As you can see, author is an object
that has another object nested in it, that is, the name object, which has two properties firstName and lastName.

Arrays

We have already used array type data, but we didn't talk about it. By default all fields in Lucene and thus in ElasticSearch are multivalued, which means that they can store multiple values.
In order to send such fields for indexing to ElasticSearch we use the JSON array type, which is nested within the opening and closing square brackets [].
As you can see in the previous example, we used the array type for characters property for our book.

Mappings

So, what can we do to index such data as that shown previously? To index arrays we don't need to do anything, we just specify the properties for such fields inside the array name.
So in our case in order to index the characters data present in the data we would need to add such mappings as these:

"characters" : {
 "properties" : {
  "name" : {"type" : "string", "store" : "yes"}
 }
}

Nothing strange, we just nest the properties section inside the array's name (which is characters in our case) and we define fields there. As a result of this mapping,
we would get the characters.name multivalued field in the index.

We perform similar steps for our author object. We call the section by the same name as is present in the data, but in addition to the properties section we also tell ElasticSearch
that it should expect the object type by adding the type property with the value object. We have the author object, but it also has the name object nested in it, so we do the same;
we just nest another object inside it. So, our mappings for that would look like the following code:

"author" : {
 "type" : "object",
 "properties" : {
  "name" : {
   "type" : "object",
   "properties" : {
    "firstName" : {"type" : "string", "store" : "yes"},
    "lastName" : {"type" : "string", "store" : "yes"}
   }
  }
 }
}

The firstName and lastName fields would appear in the index as author.name.firstName and author.name.lastName. We will check if that is true in just a second.

The rest of the fields are simple core types, so I'll skip discussing them as they were already discussed in the Schema mapping section

Final mappings

So our final mappings file that we've called structured_mapping.json looks like the following:

{
 "book" : {
  "properties" : {
   "author" : {
    "type" : "object",
    "properties" : {
     "name" : {
      "type" : "object",
      "properties" : {
       "firstName" : {"type" : "string", "store" : "yes"},
       "lastName" : {"type" : "string", "store" : "yes"}
      }
     }
    }
   },
   "isbn" : {"type" : "string", "store" : "yes"},
   "englishTitle" : {"type" : "string", "store" : "yes"},
   "originalTitle" : {"type" : "string", "store" : "yes"},
   "year" : {"type" : "integer", "store" : "yes"},
   "characters" : {
    "properties" : {
     "name" : {"type" : "string", "store" : "yes"}
    }
   },
   "copies" : {"type" : "integer", "store" : "yes"}
  }
 }
}

To be or not to be dynamic

As we already know, ElasticSearch is schemaless, which means that it can index data without the need of first creating the mappings (although we should do so if we want to control
the index structure). The dynamic behavior of ElasticSearch is turned on by default, but there may be situations where you may want to turn it off for some parts of your index.

In order to do that, one should add the dynamic property set to false on the same level of nesting as the type property for the object that shouldn't be dynamic. For example,
if we would like our author and name objects not to be dynamic, we should modify the relevant parts of the mappings file so that it looks like the following code:

   "author" : {
    "type" : "object",
    "dynamic" : false,
    "properties" : {
     "name" : {
      "type" : "object",
      "dynamic" : false,
      "properties" : {
       "firstName" : {"type" : "string", "store" : "yes"},
       "lastName" : {"type" : "string", "store" : "yes"}
      }
     }
    }
   }

However, please remember that in order to add new fields for such objects, we would have to update the mappings.

Note: You can also turn off the dynamic mapping functionality by adding the
    index.mapper.dynamic : false
property to your elasticsearch.yml configuration file


Sending the mappings to ElasticSearch

First, let's create the library index with the following command:

curl -XPUT 'localhost:9200/library'

Now, let's send our mappings for the book type:

curl -XPUT 'localhost:9200/library/book/_mapping' -d @structured_mapping.json

Now we can index our example data:

curl -XPOST 'localhost:9200/library/book/1' -d @structured_data.json

If we would like to see how our data was indexed, we can run a query like the following:

curl -XGET 'localhost:9200/library/book/_search?q=*:*&fields=*&pretty=true'

It will return the following data:
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 1,
    "max_score" : 1.0,
    "hits" : [ {
      "_index" : "library",
      "_type" : "book",
      "_id" : "1",
      "_score" : 1.0,
      "fields" : {
        "copies" : 0,
        "characters.name" : [ "Raskolnikov", "Sofia" ],
        "englishTitle" : "Crime and Punishment",
        "author.name.lastName" : "Dostoevsky",
        "isbn" : "123456789",
        "originalTitle" : "????????é??? ? ?????á???",
        "year" : 1886,
        "author.name.firstName" : "Fyodor"
      }
    } ]
  }
}

As you can see, all the fields from arrays and object types are indexed properly.
Please notice that there is, for example, the author.name.firstName field present, because ElasticSearch did flatten the data.


Extending your index structure with additional internal information

All the information provided in the previous chapters gave us a good look at what ElasticSearch is capable of, both in terms of indexing and querying.
But their coverage was not nearly complete. One thing we would like to discuss in more detail is the functionalities of ElasticSearch that are not used every day,
but can make our life easier when it comes to data handling.

Note:
Each of the following field types should be defined on an appropriate type level. So if you recall our sample mappings for our small library from Chapter 2, Searching Your Data,
we would add any of the following types under the book type mappings.


The identifier field

As you recall, each document indexed in ElasticSearch has its own identifier and type. In ElasticSearch there are two types of internal identifiers
for the documents.

The first one is the _uid field, which is the unique identifier of the document in the index and is composed of the document's identifier and the document type.
This basically means that documents of different types that are indexed into the same index can have the same document identifier yet ElasticSearch
will be able to distinguish them. This field doesn't require any additional settings; it is always indexed, but it's good to know that it exists.

The second field holding an identifier is the _id field. This field stores the actual identifier set during index time. In order to enable the indexing of the
_id field (and storing it if possible), we need to add the _id field definition just like any other property in our mappings
(although as said before, please add it in the body of the type definition). So, our sample book type definition will look like the following:

{
 "book" : {
  "_id" : {
   "index": "not_analyzed", 
   "store" : "no"
  },
  "properties" : {
  .
  .
  .
  }
 }
}

As you can see, in the previous example, we said that we want our _id field to be indexed, but not analyzed and we don't want to store it.

In addition to specifying an ID during indexing time, we can specify that we want it to be fetched from one of the fields of the indexed documents
(although this will be slightly slower because of the additional parsing needed). In order to do that we need to specify the path property with
the name of the field we want to use as the identifier value provider.
For example, if we have the book_id field in our index and we would like to use it as the value for the _id field, we could change
the previous mappings to something like the following:

{
 "book" : {
  "_id" : {
   "path": "book_id"
  },
  "properties" : {
  .
  .
  .
  }
 }
}

One last point to remember is that even when disabling the _id field, all the functionalities requiring the document's unique identifier
will still work because they will be using the _uid field instead.


The _type field

Let's say it one more time, each document in ElasticSearch is at least described by an identifier and type and if we want, we may include the type name
as the internal _type field of our indices. By default the _type field is indexed, but not stored. If we would like to store that field
we will have to change our mappings file to one like the following:

{
 "book" : {
  "_type" : {
   "store" : "yes"
  },
  "properties" : {
  .
  .
  .
  }
 }
}

We can also change the _type field in such a way that it will not be indexed, but then some queries like term queries and filters will not work.


The _all field

Allows us to create a field where the contents of other fields will be copied as well. This kind of field may be useful when we want to implement a simple search feature and search
all the data (or only the fields we copy to the _all field), but we don't want to think about field names and things like that.
By default the _all field is enabled and it contains all the data from all the fields from the index. In order to exclude a certain field from the _all field, one should use the
include_in_all property, which was discussed in chapter "Searching Your Data".
In order to completely turn off the _all field functionality (our index will be smaller without the _all field) we will modify our mappings file to one looking like the following:
{
 "book" : {
  "_all" : {
   "enabled" : false
  },
  "properties" : {
  ...
  }
 }
}

In addition to the enabled property, the _all field supports the following ones:
- store
- term_vector
- analyzer
- index_analyzer
- search_analyzer

For information about these properties please refer to chapter "Searching Your Data"


The _source field

Allows us to store the original JSON document that was sent to ElasticSearch during indexing. By default the _source field is turned on because some of the ElasticSearch functionalities
depend on it, for example, the partial update feature that was already described in Chapter "Getting Started with ElasticSearch Cluster".
In addition to that, the _source field can be used as the source of data for the highlighting functionality if a field is not stored.
But if we don't need such functionality, we can disable those fields because it causes some storage overhead.
In order to do that, we will need to set the enabled property of the _source object to false, for example, as shown in the following code:
{
 "book" : {
  "_source" : {
   "enabled" : false
  },
  "properties" : {
  ...
  }
 }
}

Because the _source field causes some storage overhead we may choose to compress information stored in that field. In order to do that, we would have to set the compress parameter to true.
Although this will shrink the index, it will make the operations made on the _source field a bit more CPU-intensive. However, ElasticSearch allows us to decide when to compress
the _source field.
Using the compress_threshold property, we can control how big the _source field's content needs to be in order for ElasticSearch to compress it.
This property accepts a size value in bytes (for example, 100b, 10kb).


The _boost field

As you may suspect, the _boost field allows us to set a default boost value for all the documents of a certain type. Imagine that we would like our book's documents to have a higher value
than all the other types of documents in the index. You may wonder, why increase the boost value of the document? If some of your documents are more important than others,
you can increase their boost value in order for ElasticSearch to know that they are more valuable. To achieve that for every single document we can use the _boost field.
So if we would like all our book documents to have the value 10.0, we can modify our mappings to something like the following:
{
 "book" : {
  "_boost" : {
   "name" : "_boost",
   "null_value" : 10.0
  },
  "properties" : {
  ...
  }
 }
}

This mapping change says that if we don't add an additional field named _boost to our documents sent for indexing the null_value value will be used as boost.
If we do add such a field, its value will be used instead of the default one.


The _index field

ElasticSearch allows us to store information about the index that the document is indexed in. We can do that by using the internal _index field. Imagine that we create daily indices,
use aliasing, and are interested to know in which daily index the returned document is stored. In such a case the _index field can be useful.

By default, the indexing of the _index field is disabled. In order to enable it, we need to set the enabled property of the _index object to true, for example:

{
 "book" : {
  "_index" : {
   "enabled" : true
  },
  "properties" : {
  ...
  }
 }
}


The _size field

Is disabled by default, allows you to automatically index the original, uncompressed size of the _source field and store it along with the documents. If we would like to enable
the _size field, we need to add the _size property and wrap the enabled property with the value of true. In addition to that, we can also set the _size field to be stored
by using the usual store property. So, if we would like our mapping to include the _size field and also want to store it:

{
 "book" : {
  "_size" : {
   "enabled": true, 
   "store" : "yes"
  },
  "properties" : {
  ...
  }
 }
}


The_timestamp field

Is disabled by default, allows us to store information about when the document was indexed. Enabling that functionality is as simple as adding the _timestamp section to our mappings
and setting the enabled property to true:

{
 "book" : {
    "_timestamp" : {
    "enabled" : true
  },
  "properties" : {
  ...
  }
 }
}

The _timestamp field is not stored, indexed, and also not analyzed by default, but you can change those two parameters to match your needs. In addition to that, the _timestamp field
is just like the normal date field so we can change its format just like we do with the usual date-based fields. In order to change the format, we need to specify the format property
with the desired format.

One more thing, instead of automatically creating the _timestamp field during document indexation, we can add the path property and set it to the name of the field from which the date
should be taken. So if we would like our _timestamp field to be based on the year field, we need to modify our mappings to something like the following:

{
 "book" : {
  "_timestamp" : {
   "enabled" : true,
   "path" : "year",
   "format" : "YYYY"
  },
  "properties" : {
  ...
  }
 }
}

As you may notice, we also modify the format of the _timestamp field in order to match the values stored in the year field.

Note: If you use the _timestamp field and you let ElasticSearch create it automatically, the value of that field will be set to the time of indexation of that document.
Please note that when using the partial document update functionality the _timestamp field will also be updated.


The _ttl field

Stands for time to live, that is, a functionality that allows us to define a life period of a document after which it will be automatically deleted. As you may expect, by default
the _ttl field is disabled and to enable it we need to add the _ttl JSON object with its enabled property set to true:

{
 "book" : {
  "_ttl" : {
   "enabled" : true
  },
  "properties" : {
  ...
  }
 }
}

If you need to provide the default expiration time for documents, just add the default property to the _ttl field definition with the desired expiration time. For example,
to have our documents deleted after 30 days, we would set the following parameters:

{
 "book" : {
  "_ttl" : {
   "enabled" : true,
   "default" : "30d"
  },
  "properties" : {
  ...
  }
 }
}

By default, the _ttl field is stored and indexed, but not analyzed and you can change those two parameters, but remember that this field needs to be not analyzed in order to work.


Getting started with highlighting

There is no better way of showing how highlighting works than making a query and looking at the results returned by ElasticSearch. So let's do that. Let's assume that we would like
to highlight the words that were matched in the title field of our documents to increase the search experience of our users. We are again looking for the word crime and we would like
to get highlighted results:

{
 "query" : {
  "term" : {
   "title" : "crime"
  }
 },
 "highlight" : {
  "fields" : {
   "title" : {}
  }
 }
}

The response for such a query would be as follows:

{
  "took" : 2,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
"hits" : {
    "total" : 1,
    "max_score" : 0.19178301,
    "hits" : [ {
      "_index" : "library",
      "_type" : "book",
      "_id" : "4",
      "_score" : 0.19178301, "_source" : { "title": "Crime and Punishment","otitle": "????????é??? ? ?????á???","author": "Fyodor Dostoevsky","year": 1886,"characters": ["Raskolnikov", "Sofia Semyonovna Marmeladova"],"tags": [],"copies": 0, "available" : true},
      "highlight" : {
        "title" : [ "<em>Crime</em> and Punishment" ]
      }
    } ]
  }
}

As you can see, apart from the standard information we got from ElasticSearch, there is a new section called highlight. Here, ElasticSearch used the <em> HTML tag as the beginning of the
highlight section and its closing counterpart to close the section. This is the default behavior of ElasticSearch, but we will learn how to change that.


Field configuration

In order to perform highlighting, the original content of the field needs to be present—we have to set to store the fields that we will use for highlighting. However, it is possible to use
the _source field if fields are not stored and ElasticSearch will use one or the other automatically.


Under the hood

ElasticSearch uses Apache Lucene under the hood and highlighting is one of the features of that library. Lucene provides two types of highlighting implementation—the standard one, which we
just used and the second one called FastVectorHighlighter, which needs term vectors and positions to be able to work. ElasticSearch chooses the right highlighter implementation automatically.
If the field is configured with the term_vector property set to with_positions_offsets, FastVectorHighlighter will be used; otherwise the default Lucene highlighter will be used.

However, you have to remember that having term vectors will cause your index to be larger, but the highlighting will take less time to be executed. Also, FastVectorHighlighter is recommended
for fields that store a lot of data in them.


Configuring HTML tags

As we already mentioned, it is possible to change the default HTML tags to the ones we would like to use. For example, let's assume that we would like to use the standard HTML <b> tag for
highlighting. In order to do that, we should set the pre_tags and post_tags properties (those are arrays) to <b> and </b>. Because both of these properties are arrays, we can include more
than one tag and ElasticSearch will use each of the defined tags to highlight different words:

{
 "query" : {
  "term" : {
   "title" : "crime"
  }
 },
 "highlight" : {
 "pre_tags" : [ "<b>" ],
  "post_tags" : [ "</b>" ],
  "fields" : {
   "title" : {}
  }
 }
}

The result returned by ElasticSearch to the previous query would be the following:

{
  "took" : 2,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 1,
    "max_score" : 0.19178301,
    "hits" : [ {
      "_index" : "library",
      "_type" : "book",
      "_id" : "4",
      "_score" : 0.19178301, "_source" : { "title": "Crime and Punishment","otitle": "????????é??? ? ?????á???","author": "Fyodor Dostoevsky","year": 1886,"characters": ["Raskolnikov", "Sofia Semyonovna Marmeladova"],"tags": [],"copies": 0, "available" : true},
      "highlight" : {
      "title" : [ "<b>Crime</b> and Punishment" ]
      }
    } ]
  }
}

As you can see, the word Crime in title was surrounded by the tags of our choice.


Controlling highlighted fragments

ElasticSearch allows us to control the number of highlighted fragments returned, their sizes, and also exposes two of the properties we are allowed to use.

The first one, number_of_fragments, defines the number of fragments returned by ElasticSearch (it defaults to 5). Setting this property to 0 causes the whole field to be returned,
which can be handy for short fields; however, it can be expensive for longer fields.

The second property, fragment_size, lets us specify the maximum length of the highlighted fragments in characters and defaults to 100.

Global and local settings

The highlighting properties we discussed previously can be set both on a global basis and on a per field basis. The global ones will be used for all the fields that don't overwrite them
and should be placed on the same level as the fields section of your highlighting, for example:

{
 "query" : {
  "term" : {
   "title" : "crime"
  }
 },
 "highlight" : {
  "pre_tags" : [ "<b>" ],
  "post_tags" : [ "</b>" ],
  "fields" : {
   "title" : {}
  }
 }
}

You can also set the properties for each field. For example, if we would like to keep the default behavior for all the fields except our title field, we would do the following:

{
 "query" : {
  "term" : {
   "title" : "crime"
  }
 },
 "highlight" : {
  "fields" : {
   "title" : { "pre_tags" : [ "<b>" ], "post_tags" : [ "</b>" ] }
  }
 }
}

As you can see, instead of placing the properties on the same level as the fields section we placed them inside the empty JSON object that specifies the field title's behavior.
Of course, each field can be configured to use different properties


Require matching

  



